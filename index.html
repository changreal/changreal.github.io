<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/zrmm.jpg">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/zrmm.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/zrmm.jpg">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Gemini","version":"8.0.0-rc.5","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}};
  </script>

  <meta name="description" content="博客">
<meta property="og:type" content="website">
<meta property="og:title" content="Changreal">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Changreal">
<meta property="og:description" content="博客">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Changreal">
<meta property="article:tag" content="rrz的动感地带">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://yoursite.com/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Changreal</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Changreal</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">睿睿的动感地带</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Changreal"
      src="/images/zrmm.jpg">
  <p class="site-author-name" itemprop="name">Changreal</p>
  <div class="site-description" itemprop="description">博客</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </section>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">
      

      
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/26/%E7%9D%BF%E7%9D%BF%E7%9A%84NLP%E5%AE%9E%E8%B7%B5%E6%8C%87%E5%8D%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zrmm.jpg">
      <meta itemprop="name" content="Changreal">
      <meta itemprop="description" content="博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Changreal">
    </span>

    
    
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/26/%E7%9D%BF%E7%9D%BF%E7%9A%84NLP%E5%AE%9E%E8%B7%B5%E6%8C%87%E5%8D%97/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2020-08-26 22:13:13 / Modified: 22:12:57" itemprop="dateCreated datePublished" datetime="2020-08-26T22:13:13+08:00">2020-08-26</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="睿睿的NLP实践指南"><a href="#睿睿的NLP实践指南" class="headerlink" title="睿睿的NLP实践指南"></a>睿睿的NLP实践指南</h1><p>[TOC]</p>
<h2 id="数据构成"><a href="#数据构成" class="headerlink" title="数据构成"></a>数据构成</h2><h3 id="batch、iterations、epochs"><a href="#batch、iterations、epochs" class="headerlink" title="batch、iterations、epochs"></a>batch、iterations、epochs</h3><p>一句话解释：1000个数据，batch_size设置为500，那么需要2次iterations，完成1次epoch。</p>
<h4 id="batch"><a href="#batch" class="headerlink" title="batch"></a>batch</h4><p><strong>使用batch的目的</strong></p>
<p>现在的梯度下降基本都是基于mini-batch gradient decent的，小批的梯度下降。这种方法把数据分为若干个批，按批来更新参数，这样，一个批中的一组数据共同决定了本次梯度的方向，下降起来就不容易跑偏，减少了随机性。另一方面因为批的样本数与整个数据集相比小了很多，计算量也不是很大。因此，深度学习框架中，经常会应用<code>batch_size</code>。</p>
<p><strong>batch的数据准备</strong></p>
<p>在 NLP 中，文本数据大都是变长的，为了能够做 batch 的训练，需要 padding 到相同的长度，并在实际训练中忽略 padding 部分的影响。下图是pytorch中 pack_padded_sequence 内部按有效长度逆序排列之后，生成的batch_sizes集合。</p>
<img src="H:\图片\typora images\代码记录\image-20200719121634530.png" alt="image-20200719121634530" style="zoom: 50%;" />



<p>在LSTM中的batch_size和宏观的批batch_size是不同的，LSTM会遇到<code>seg_length</code>，<code>batch_size = num_steps * seg_length</code>。</p>
<p><strong>race的batch</strong></p>
<p>目前我假设race数据集，一个batch就是一篇文章，而一个batch的example数量就是batch_size，每个example由该篇文章不同的问题和选项一一构成，也就是说一篇文章为一批次送入模型。</p>
<h4 id="iterations"><a href="#iterations" class="headerlink" title="iterations"></a>iterations</h4><p>每一次迭代都是一次权重更新，每一次权重更新需要<code>batch_size</code>个数据进行forward运算得到损失函数，再BP算法更新参数。<strong>1个iteration等于使用<code>batch_size</code>个样本训练一次。</strong></p>
<h4 id="epochs"><a href="#epochs" class="headerlink" title="epochs"></a>epochs</h4><p>epochs被定义为向前\向后传播中所有批次的单次训练迭代，即<strong>最少训练完整个样本集所需的次数</strong>。也可以说，epochs指训练过程中数据将被“轮”多少次。</p>
<p>1 <strong>epoch</strong> = numbers of <strong>iterations</strong> = N = 训练样本的数量/<strong>batch_size</strong></p>
<h3 id="模型输入"><a href="#模型输入" class="headerlink" title="模型输入"></a>模型输入</h3><p>一定要记住模型<u>训练样例的的输入组成</u>，比如一个race数据集，一个example的输入是：[passage<sub>i</sub>, question<sub>ij</sub>, option<sub>ijk</sub>]，也就是说是一篇passage、question、单个option构成输入，喂入模型。</p>
<h4 id="输入影响matching-attention"><a href="#输入影响matching-attention" class="headerlink" title="输入影响matching attention"></a>输入影响matching attention</h4><p>为了生成这样的输入样例，要进行passage-option的交互，就要复制 <code>question_num * option_num</code>次passage，要进行passage-question的交互，就要复制<code>question_num</code>次passage。要question-option的交互，就复制<code>option_num</code>次的question。</p>
<p>复制的方法可以用<code>.repeat()</code>结合<code>.view()</code>方法来实现，方法使用说明具体见下文。</p>
<p>这样就生成了许多的example，从而喂入模型的examples训练样例就可以看做是：**[batch_size, length, dim]<strong>，也就是说，通过上面的复制处理，</strong>使得batch_size能够数量相等、并一一对应**。</p>
<ul>
<li><p>如果是passage-option：表示的是passage中每一个单词对option中每一个单词的注意力</p>
<blockquote>
<p>passages的输入：(len(passages), passage_length, dim)，注：这里的passage_length是由多个sequence_length组合起来的。</p>
<p>options的输入：(len(options), option_length, dim)，这里len(options)=len(passages)=batch_size</p>
<p>passage-option的matching就是：（batch_size, passage_length, option_length）</p>
</blockquote>
</li>
<li><p>passage-question：表示的是passage中每一个单词对question中每一个单词的注意力</p>
<blockquote>
<p>passages的输入：(len(passages), passage_length, dim)，注：这里的passage_length是由多个sequence_length组合起来的。</p>
<p>questions的输入：(len(questions), question_length, dim)，这里len(Q)=len(P)=batch_size</p>
<p>passage-question的matching就是：（batch_size, passage_length, question_length）</p>
</blockquote>
</li>
<li><p>question-option</p>
<blockquote>
<p>question-option的matching就是：（batch_size, question_length, option_length）</p>
</blockquote>
</li>
</ul>
<h4 id="PLMs输入"><a href="#PLMs输入" class="headerlink" title="PLMs输入"></a>PLMs输入</h4><p><strong>如果是直接进行PLMs的输入处理，以后遇到相关代码了这里补上</strong>。</p>
<h3 id="不同层次的Level"><a href="#不同层次的Level" class="headerlink" title="不同层次的Level"></a>不同层次的Level</h3><h4 id="word-level到sentence-level"><a href="#word-level到sentence-level" class="headerlink" title="word-level到sentence-level"></a>word-level到sentence-level</h4><p>比如看代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">l_hidden = self.l_encoder([co_match_hier, d_l_len.repeat(<span class="number">1</span>, o_embs.size(<span class="number">1</span>)).view(<span class="number">-1</span>)]) </span><br><span class="line"><span class="comment"># [(documents * option_num * sents_num, sent_len_max,  mem_dim * 8), (documents * sents_num * option_num )]</span></span><br><span class="line"><span class="comment"># 返回：(documents * option_num * sents_num, sent_len_max, dim )，即(batch_size,sentence_i_length,dim)，</span></span><br><span class="line"><span class="comment"># 也就是说：得到每个句子的word-level级的表示</span></span><br></pre></td></tr></table></figure>

<p>这里，经过encoder（是一个lstm）输出得到的l_hidden是一个word-level的表示，维度是<code>(documents * option_num * sents_num, sent_len_max, dim )</code>，看这里的构成也能看出来，<code>sent_len_max</code>这个维度的构成就是一个句子中的每个词，因此这个输出是word-level的。那么如何把word-level转化为sentence-level呢？co-matching的作者用了最大池化的方法（<u>当然，也可以不用最大池化，取最后一个单词的隐藏状态也可以</u>），从而<strong>由word-level得到sentence-level的句子级别的语义表示</strong>，具体见下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">l_hidden_pool, _ = l_hidden.max(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># (documents * option_num * sents_num,  dim )，即(batch_size, dim)</span></span><br></pre></td></tr></table></figure>

<p>在句子length（也就是词的构成）这一维度做最大池化，找出最能代表这个句子的表示，<u>词这个维度就消掉了</u>，得到的是sentence-level即句子级别的语义表示，共有<code>sents_num</code>个。</p>
<h4 id="sentence-level到document-level"><a href="#sentence-level到document-level" class="headerlink" title="sentence-level到document-level"></a>sentence-level到document-level</h4><p>由上文可知，<strong>从sentence-level再转到document-level</strong>的方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">h_hidden = self.h_encoder([l_hidden_pool.view(d_embs.size(<span class="number">0</span>)*o_embs.size(<span class="number">1</span>), d_embs.size(<span class="number">1</span>), <span class="number">-1</span>), d_h_len.view(<span class="number">-1</span>, <span class="number">1</span>).repeat(<span class="number">1</span>, o_embs.size(<span class="number">1</span>)).view(<span class="number">-1</span>)])</span><br><span class="line"><span class="comment"># [(documents * option_num , sents_num, mem_dim * 2), (documents * options_num)]</span></span><br><span class="line"><span class="comment"># 返回ht（h_hidden）：(documents * option_num , sents_num, mem_dim)，ht是sentence-level句子级的语义表示</span></span><br><span class="line">h_hidden_pool, _ = h_hidden.max(<span class="number">1</span>)  <span class="comment"># 得到每个文档的表示，就是找出每个句子的代表表示hs从而构成这个文档，于是句子维度消失了</span></span><br><span class="line"><span class="comment"># (documents * option_num , mem_dim)</span></span><br></pre></td></tr></table></figure>

<p>也就是先构造到sentence-level的输入，即<code>(documents * option_num , sents_num, dim)</code>，然后在<code>sents_num</code>的这一维度（也就是一篇文档的句子构成）做最大池化，从而得到最能代表这篇文档的表示，即document-level的语义表示，共有<code>option_num</code>（即每个question的选项数）个document-level的语义表示。</p>
<h3 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h3><p>比如这样的目标函数：</p>
<p>h<sup>t</sup>表示的是question和passage的matching关系（我觉得表示的是passage和option的关系…），从而用它们做交叉熵，得到来计算答案的损失函数。<br>$$<br>\begin{equation}L\left(\mathbf{A}<em>{i} \mid \mathbf{P}, \mathbf{Q}\right)=-\log \frac{\exp \left(\mathbf{w}^{T} \mathbf{h}</em>{i}^{t}\right)}{\sum_{j=1}^{4} \exp \left(\mathbf{w}^{T} \mathbf{h}_{j}^{t}\right)}\end{equation}<br>$$<br><strong>logits</strong></p>
<p>比如标签的形状是labels=(batch_size,4),它是one_hot形式的，比如第一个值是(0,1,0,0)那就表示batch_size个样本中的第一个样本的第二个选项是正确答案。选项的每个h<sup>t</sup>通过一个网络层，得到四个张量，每一个值都是<code>(batch_size,1)</code>形状的，然后将张量堆叠在一起就是(batch_size,4)，这就是logits。</p>
<p>之后做预测的时候就是argmax(logits)得到的值就是预测的选项，那么损失函数自然也就是将logits与labels做交叉熵。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">o_rep = h_hidden_pool.view(d_embs.size(<span class="number">0</span>), o_embs.size(<span class="number">1</span>), <span class="number">-1</span>)</span><br><span class="line"><span class="comment"># (documents, option_num , mem_dim)，准备logits</span></span><br><span class="line">output = torch.nn.functional.log_softmax( self.rank_module(o_rep).squeeze(<span class="number">2</span>) ) </span><br><span class="line"><span class="comment"># (documents, option_num , mem_dim) -&gt; ((documents, option_num , 1)) -&gt; ((documents, option_num))</span></span><br><span class="line"><span class="comment"># softmax后输出：(documents, option_num)，从而找出每篇document最可能性的option！</span></span><br></pre></td></tr></table></figure>



<h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p>先从single example开始，再到batches吧。</p>
<p>及时记录batch数据格式</p>
<p>词嵌入这些 ，pt先直接run，有了以后就快了</p>
<p><strong>查看gpu</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>

<p>显存：<a target="_blank" rel="noopener" href="https://blog.csdn.net/zhuiqiuk/article/details/90973240?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.compare&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.compare">https://blog.csdn.net/zhuiqiuk/article/details/90973240?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.compare&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.compare</a></p>
<h2 id="公式说明"><a href="#公式说明" class="headerlink" title="公式说明"></a>公式说明</h2><p><strong>隐层操作</strong></p>
<img src="H:\图片\typora images\代码记录\image-20200719124932189.png" alt="image-20200719124932189" style="zoom:50%;" />

<p>Q：为什么这里做element_wise减法和element_wise乘法再向量拼接呢？</p>
<blockquote>
<p>A：H_q是passage关注question方面的信息后的新表示，Hp是passage的上下文表示，那么这种减法和乘法就可以将这两方面的信息进行比较，更好的构造出交互的特征，再拼接起来。这比简单直接的向量拼接效果更好。</p>
</blockquote>
<h2 id="数据处理代码"><a href="#数据处理代码" class="headerlink" title="数据处理代码"></a>数据处理代码</h2><h3 id="向量计算"><a href="#向量计算" class="headerlink" title="向量计算"></a>向量计算</h3><h4 id="点乘"><a href="#点乘" class="headerlink" title="点乘"></a>点乘</h4><ul>
<li><p>不同维的向量可以相点乘，将空缺的维以0补全，令维数相同，然后再相乘。</p>
</li>
<li><p>点乘，只有在向量的列为1或与另一个向量的列相等时，才能进行点乘运算</p>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/wu18663419760/article/details/93137954">https://blog.csdn.net/wu18663419760/article/details/93137954</a></p>
<blockquote>
<p>比如说w向量：w(2,2)；x向量：x(2,2,3)，</p>
<p>利用矩阵维度变换后，</p>
<ul>
<li><p>对w进行维度扩张：w-&gt;w(2,1,2)；</p>
</li>
<li><p>对x的第二维和第三维度互换：x-&gt;x(2,3,2)，</p>
</li>
</ul>
<p>从而w与x点乘。</p>
</blockquote>
<h4 id="向量乘法"><a href="#向量乘法" class="headerlink" title="向量乘法"></a>向量乘法</h4><ul>
<li><p><code>torch.mul(input, other, out)</code> 和 <code>*</code>等价（attentioin中可以用到）</p>
<p>点乘，input和other需要是<strong>可广播</strong>的类型</p>
</li>
</ul>
<ul>
<li><p><code>torch.dot(input, tensor) -&gt; Tensor</code></p>
<p>用来计算两个tensors的内积，不支持广播。</p>
<img src="D:\Pictures\typora images\睿睿的NLP实践指南\equation.svg" style="zoom:80%;" />
</li>
<li><p><code>torch.mm(input, mat2, out=None) → Tensor</code></p>
<p>计算两个二维矩阵的乘法，不支持广播</p>
<blockquote>
<p>如果input是（n x m），mat2是（m x p），out将会是（n x p）</p>
</blockquote>
</li>
</ul>
<ul>
<li><p><code>torch.bmm(input, mat2, out=None) -&gt; Tensor</code></p>
<p>用于计算一个batch里的二维矩阵乘法，input和mat2都必须是3D矩阵，<strong>不支持广播</strong>（广播见torhc.matmul）</p>
<blockquote>
<p> input是（b x n x m）的tensor，mat2是（b x m x p）的tensor，那么out会是（b x n x p）的tensor。</p>
</blockquote>
</li>
</ul>
<ul>
<li><p><code>torch.matmul(input, other, out=None) -&gt; Tensor</code></p>
<p><code>matmul</code>比<code>bmm</code>功能更强大，但是<code>bmm</code>语义非常明确</p>
<p>根据官网文档，也就是说：</p>
<ul>
<li><p>如果都是1维的，返回的是标量（scalar）；</p>
</li>
<li><p>如果都是2维的，与torch.mm等价</p>
</li>
<li><p>如果input是vector，other是matrix，会在vector增加一个维度</p>
<blockquote>
<p>vector shape变成了：（1 x N）</p>
<p>matrix shape：（N x M）</p>
<p>然后类似torch.matmul，相乘之后，变成（1 x M）</p>
<p>在结果中再将增加的这个1维去掉</p>
</blockquote>
</li>
<li><p>如果input是matrix，other是vector，vector会被扩充一个维度</p>
<blockquote>
<p>也类似调用torch.matmul()</p>
</blockquote>
</li>
</ul>
<img src="https://i.loli.net/2020/07/25/MemJPIjiyK4D5bc.png" style="zoom:90%;" />

<p>代码样例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">  &gt;&gt;&gt; <span class="comment"># vector x vector</span></span><br><span class="line">  &gt;&gt;&gt; tensor1 = torch.randn(<span class="number">3</span>)</span><br><span class="line">  &gt;&gt;&gt; tensor2 = torch.randn(<span class="number">3</span>)</span><br><span class="line">  &gt;&gt;&gt; torch.matmul(tensor1, tensor2).size()</span><br><span class="line">torch.Size([])</span><br><span class="line">  &gt;&gt;&gt; <span class="comment"># matrix x vector</span></span><br><span class="line">  &gt;&gt;&gt; tensor1 = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">  &gt;&gt;&gt; tensor2 = torch.randn(<span class="number">4</span>)</span><br><span class="line">  &gt;&gt;&gt; torch.matmul(tensor1, tensor2).size()</span><br><span class="line">  torch.Size([<span class="number">3</span>])</span><br><span class="line">  &gt;&gt;&gt; <span class="comment"># batched matrix x broadcasted vector</span></span><br><span class="line">  &gt;&gt;&gt; tensor1 = torch.randn(<span class="number">10</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">  &gt;&gt;&gt; tensor2 = torch.randn(<span class="number">4</span>)</span><br><span class="line">  &gt;&gt;&gt; torch.matmul(tensor1, tensor2).size()</span><br><span class="line">  torch.Size([<span class="number">10</span>, <span class="number">3</span>])</span><br><span class="line">  &gt;&gt;&gt; <span class="comment"># batched matrix x batched matrix</span></span><br><span class="line">  &gt;&gt;&gt; tensor1 = torch.randn(<span class="number">10</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">  &gt;&gt;&gt; tensor2 = torch.randn(<span class="number">10</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">  &gt;&gt;&gt; torch.matmul(tensor1, tensor2).size()</span><br><span class="line">  torch.Size([<span class="number">10</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br><span class="line">  &gt;&gt;&gt; <span class="comment"># batched matrix x broadcasted matrix</span></span><br><span class="line">  &gt;&gt;&gt; tensor1 = torch.randn(<span class="number">10</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">  &gt;&gt;&gt; tensor2 = torch.randn(<span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">  &gt;&gt;&gt; torch.matmul(tensor1, tensor2).size()</span><br><span class="line">  torch.Size([<span class="number">10</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h4 id="广播"><a href="#广播" class="headerlink" title="广播"></a>广播</h4><p>如果以下规则成立，则两个张量是“可广播的”：</p>
<ol>
<li>每个张量<strong>至少有一个维度</strong>。</li>
<li>当迭代尺寸时，从<strong>尾部</strong>尺寸开始，尺寸必须<strong>相等</strong>，或者<strong>其中一个尺寸为1</strong>，或者<strong>尺寸不存在</strong>。</li>
</ol>
<p>官方举例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=torch.empty(<span class="number">5</span>,<span class="number">7</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y=torch.empty(<span class="number">5</span>,<span class="number">7</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># same shapes are always broadcastable (i.e. the above rules always hold)</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=torch.empty((<span class="number">0</span>,))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y=torch.empty(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"><span class="comment"># x and y are not broadcastable, because x does not have at least 1 dimension</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># can line up trailing dimensions</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=torch.empty(<span class="number">5</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y=torch.empty(  <span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># x and y are broadcastable.</span></span><br><span class="line"><span class="comment"># 1st trailing dimension: both have size 1</span></span><br><span class="line"><span class="comment"># 2nd trailing dimension: y has size 1</span></span><br><span class="line"><span class="comment"># 3rd trailing dimension: x size == y size</span></span><br><span class="line"><span class="comment"># 4th trailing dimension: y dimension doesn&#x27;t exist</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># but:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=torch.empty(<span class="number">5</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y=torch.empty(  <span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># x and y are not broadcastable, because in the 3rd trailing dimension 2 != 3</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>广播计算例子：</p>
<p>1）维度不同的话，会在少维度的那个向量前面加1维</p>
<p>2）在每个维度上，会取大维度的那个向量维度作为最大的维度</p>
<p>(mul和*会自动broadcaset到所有batch)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># can line up trailing dimensions to make reading easier</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=torch.empty(<span class="number">5</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y=torch.empty(  <span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(x+y).size()</span><br><span class="line">torch.Size([<span class="number">5</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># but not necessary:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=torch.empty(<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y=torch.empty(<span class="number">3</span>,<span class="number">1</span>,<span class="number">7</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(x+y).size()</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">1</span>, <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=torch.empty(<span class="number">5</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y=torch.empty(<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(x+y).size()</span><br><span class="line">RuntimeError: The size of tensor a (<span class="number">2</span>) must match the size of tensor b (<span class="number">3</span>) at non-singleton dimension <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>但是in-place操作不允许广播拓展：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=torch.empty(<span class="number">5</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y=torch.empty(<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(x.add_(y)).size()</span><br><span class="line">torch.Size([<span class="number">5</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># but:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=torch.empty(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y=torch.empty(<span class="number">3</span>,<span class="number">1</span>,<span class="number">7</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(x.add_(y)).size()</span><br><span class="line">RuntimeError: The expanded size of the tensor (<span class="number">1</span>) must match the existing size (<span class="number">7</span>) at non-singleton dimension <span class="number">2.</span></span><br></pre></td></tr></table></figure>



<h3 id="a的最大化"><a href="#a的最大化" class="headerlink" title="a的最大化"></a>a的最大化</h3><p>把第0维度看成句子，第1维度看成词，第2维度看成词嵌入维度，因此a.max(1)就是在一句话的所有词的表示里找max，找出最能代表这个词的表示！</p>
<img src="H:\图片\typora images\代码记录\image-20200718192810026.png" alt="image-20200718192810026" style="zoom: 67%;" />

<h3 id="关于repeat与view结合重构矩阵的注意点"><a href="#关于repeat与view结合重构矩阵的注意点" class="headerlink" title="关于repeat与view结合重构矩阵的注意点"></a>关于repeat与view结合重构矩阵的注意点</h3><p>如这行代码：</p>
<img src="H:\图片\typora images\代码记录\image-20200718181238828.png" alt="image-20200718181238828" style="zoom:110%;" />

<p>这个代码的目的是，在第0维这个单位进行复制一定量的数据，也就是说在data[i]~data[i+n]的值是一样的。</p>
<p>为什么这里要先在第1维repeat后，再view回0维，而不是直接在0维repeat呢？</p>
<p>来做一个实验就知道了：</p>
<p>a = torch.randn(2,2,2)</p>
<img src="H:\图片\typora images\代码记录\image-20200718225359629.png" alt="image-20200718225359629" style="zoom:80%;" />

<p>a.repeat(2,1,1)  =&gt; (4,2,2)</p>
<img src="H:\图片\typora images\代码记录\image-20200718180334001.png" alt="image-20200718180334001" style="zoom:67%;" />

<p>a.repeat(1,2,1) =&gt; (2,4,2)</p>
<img src="H:\图片\typora images\代码记录\image-20200718180345090.png" alt="image-20200718180345090" style="zoom:67%;" />

<p>b =a.repeat(1,2,1).view(4,2,2)</p>
<img src="H:\图片\typora images\代码记录\image-20200718180643772.png" alt="image-20200718180643772" style="zoom:67%;" />



<p>比较一下a.repeat(2,1,1)和a.repeat(1,2,1).view(4,2,2)，两者都是(4,2,2)维度的矩阵</p>
<img src="H:\图片\typora images\代码记录\image-20200718181123505.png" alt="image-20200718181123505" style="zoom: 50%;" />

<img src="H:\图片\typora images\代码记录\image-20200718181007331.png" alt="image-20200718181007331" style="zoom: 50%;" />

<p>也就是说，<strong>希望得到的是ii…repeat次数..i， i+1..repeat次数…i+1的数据矩阵构成的话，就要在所期望的重构的维度的后面一个维度先repeat，再view填充回来</strong>。</p>
<p>再做个实验：</p>
<p>比如a.shape==(2,3,2)，要在第1维进行重复数据，我猜想是a.repeat(1,1,2)，再a.view(2,6,2)</p>
<p>验证：</p>
<img src="H:\图片\typora images\代码记录\image-20200718181932762.png" alt="image-20200718181932762" style="zoom:80%;" />

<img src="H:\图片\typora images\代码记录\image-20200718182023759.png" alt="image-20200718182023759" style="zoom: 67%;" />

<p>结果正确。</p>
<p><strong>view</strong></p>
<p>使用view时报错：<em>RuntimeError: view size is not compatible with input tensor’s size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(…) instead.</em></p>
<p>两种解决办法：1）按照提示使用reshape代替；2）将变量先转为<em>contiguous ，再进行view:</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d_hidden_3d = d_hidden.contiguous().view(d_embs.size(<span class="number">0</span>), d_embs.size(<span class="number">1</span>) * d_embs.size(<span class="number">2</span>), d_hidden.size(<span class="number">-1</span>))</span><br></pre></td></tr></table></figure>



<h3 id="pytorch的损失函数"><a href="#pytorch的损失函数" class="headerlink" title="pytorch的损失函数"></a>pytorch的损失函数</h3><p>NLLLoss：<a target="_blank" rel="noopener" href="https://blog.csdn.net/GentleCP/article/details/106602179">https://blog.csdn.net/GentleCP/article/details/106602179</a></p>
<p>18个损失函数：<a target="_blank" rel="noopener" href="https://blog.csdn.net/u011995719/article/details/85107524">https://blog.csdn.net/u011995719/article/details/85107524</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/26/KMRC%EF%BC%88%E6%9B%B4%E6%96%B0%E4%B8%AD%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zrmm.jpg">
      <meta itemprop="name" content="Changreal">
      <meta itemprop="description" content="博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Changreal">
    </span>

    
    
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/26/KMRC%EF%BC%88%E6%9B%B4%E6%96%B0%E4%B8%AD%EF%BC%89/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2020-08-26 22:13:13 / Modified: 22:12:58" itemprop="dateCreated datePublished" datetime="2020-08-26T22:13:13+08:00">2020-08-26</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="KMRC"><a href="#KMRC" class="headerlink" title="KMRC"></a>KMRC</h2><p>[TOC]</p>
<h3 id="Knowledge-Resources分类"><a href="#Knowledge-Resources分类" class="headerlink" title="Knowledge Resources分类"></a>Knowledge Resources分类</h3><p>为了理解自然语言，需要语言学知识来确定文本的句法、语义结构，再进一步使用通识、常识知识来增强对结构的理解，知识可以为分为：</p>
<h4 id="linguistic-knowledge"><a href="#linguistic-knowledge" class="headerlink" title="linguistic knowledge"></a>linguistic knowledge</h4><ul>
<li>annotated linguistic corpora</li>
<li>lecical resources，比如wordNet, VerbNet, FrameNet</li>
</ul>
<p><strong>各种类型的语义信息</strong></p>
<ul>
<li>POS, NER embeddings</li>
<li>semantic connections ，比如同义词</li>
<li>structural embeddings，比如基于parsing trees来构造input embeddings</li>
</ul>
<h4 id="common-knowledge"><a href="#common-knowledge" class="headerlink" title="common knowledge"></a>common knowledge</h4><p>需要specific facts about the world that are often explicitly stated.</p>
<h4 id="commonsenses-knowledge"><a href="#commonsenses-knowledge" class="headerlink" title="commonsenses knowledge"></a>commonsenses knowledge</h4><p>大多数人都知道，并不需要explicitly stated.</p>
<p>有intuitive psychoogy, intuitive physics两种类型的常识，对人类推理和下决定起决定作用。</p>
<p>common knowledge 与commonsenses knowledge的不同是，后者需要对语言中各种层次的概念有深度的理解</p>
<h3 id="2019-EMNLP-Pingan-Smart-Health-and-SJTU-at-COIN-Shared-Task-utilizing-Pre-trained-Language-Models-and-Common-sense-Knowledge-in-Machine-Reading-Tasks"><a href="#2019-EMNLP-Pingan-Smart-Health-and-SJTU-at-COIN-Shared-Task-utilizing-Pre-trained-Language-Models-and-Common-sense-Knowledge-in-Machine-Reading-Tasks" class="headerlink" title="2019 EMNLP_Pingan Smart Health and SJTU at COIN - Shared Task: utilizing Pre-trained Language Models and Common-sense Knowledge in Machine Reading Tasks"></a>2019 EMNLP_Pingan Smart Health and SJTU at COIN - Shared Task: utilizing Pre-trained Language Models and Common-sense Knowledge in Machine Reading Tasks</h3><h4 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h4><h4 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h4><p>无代码</p>
<p>模型：target task1：类似SemEval 2018 Task 11  ，target task2：ReCoRD  ，RACE,SWAG(后两者用于第一阶段微调)</p>
<ul>
<li><p>对于task1：用XLNet先在race上fine-tune，然后再在swag上fine-tune从而获得知识，最后再在target task上fine-tune（多阶段fine-tune）。</p>
<blockquote>
<p>这么设置的原因的race很大，为了能更好的泛化，swag数据集的queries和target  task很相似，并且需要常识推理，最后在task1上fine-tune能更好的收敛。</p>
</blockquote>
</li>
<li><p>对于task2：吧ptm词嵌入和wordNet上下文词嵌入拼接，再采取一系列post-processing strategies来预测。</p>
<blockquote>
<p>fuse的过程：KG embedding 使用DisMult，首先使用Aho-Corasick算法把passage中的命名实体匹配到WordNet，然后P中在wordnet中有的token会给同样的向量，P中不在任何明明实体的token会给一个0向量。让后具体见下图。</p>
</blockquote>
</li>
</ul>
<p>task2模型结构与知识注入方式：</p>
<img src="https://i.loli.net/2020/07/10/4sXUSpl1NfKwDHh.png" style="zoom:90%;" />



<img src="https://i.loli.net/2020/07/10/bxJnNGgLqfipeYC.png" style="zoom:80%;" />



<h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><img src="https://i.loli.net/2020/07/10/LPoKjGZEpl69Vm3.png" style="zoom:80%;" />

<img src="https://i.loli.net/2020/07/10/ZV2Dw173rFEQAJ8.png" style="zoom:80%;" />

<h3 id="2020-arXiv-K-ADAPTER-Infusing-Knowledge-into-Pre-Trained-Models-with-Adapters"><a href="#2020-arXiv-K-ADAPTER-Infusing-Knowledge-into-Pre-Trained-Models-with-Adapters" class="headerlink" title="2020 arXiv_K-ADAPTER: Infusing Knowledge into Pre-Trained Models with Adapters"></a>2020 arXiv_K-ADAPTER: Infusing Knowledge into Pre-Trained Models with Adapters</h3><h4 id="概要-1"><a href="#概要-1" class="headerlink" title="概要"></a>概要</h4><p><strong>动机</strong></p>
<p>之前的知识引入预训练模型主要集中与通过设计 knowledge-driven 的训练目标来增强standard LM的训练目标，然后通过多任务学习的方式更新模型的全部参数，它们的问题是：</p>
<ul>
<li>无法进行终身学习（continual learning）<ul>
<li>模型的参数在引入新知识的时候需要重新训练</li>
<li>对于已经学到的知识来说，会造成灾难性遗忘（catastrophic forgetting）</li>
</ul>
</li>
<li>模型产生的是耦合的表示（entangled representations）<ul>
<li>为进一步探究引入不同知识的作用/影响带来困难</li>
</ul>
</li>
</ul>
<p>因此，作者提出了K-Adapter，以一种简单灵活的方式把知识infuse进PTMs，并且支持<strong>continual knowledge infusion</strong>和产生<strong>disentangled representations（耦合的表示）</strong>。具体而言就是，<strong>固定住预训练模型的参数</strong>，然后引入<strong>adapter（a neural adapter for each kind of infused knowledge）</strong>来接到预训练模型的输出上，每个adapter是独立的，针对不同的知识（比如factual knowledge，linguistic knowledge）<strong>各自独立预训练</strong>，从而实现知识引入。</p>
<p>也就是说，Adapter可以看做是一个 knowledge-specific 模型，可以作为一个<strong>插件</strong>，加在PLM外部，输入包含PLM中间层输出的隐状态，一种知识类型对应于一个Adapter，一个PLM可以连接多个Adapter；</p>
<p>the training process is memory efficient，并且结合roberta有很少的训练参数。</p>
<p><strong>贡献</strong></p>
<ul>
<li>K-Adapter，一个灵活的方法，支持continual knowledge infusion into large PTMs，最终的模型包含一个PLM和两个Adapter；</li>
<li>They infuse factual knowledge and linguistic knowledge，然后两种adapters都在下游任务表现良好</li>
<li>通过在三种下游任务（关系分类、命名实体分类、qa）中fine-tuning的方式，结果很好。</li>
</ul>
<p><strong>时间会议</strong>：2020，arxiv，会议还不知道</p>
<p><strong>QA数据集</strong>：CosmosQA，SearchQA,  Quasar-T QA</p>
<p><strong>本文引入的知识类型</strong></p>
<ul>
<li>factual knowledge，将Wikipedia文本对齐到Wikidata三元组</li>
<li>linguistic knowledge，对web文本进行依存分析得到</li>
</ul>
<p><strong>思考</strong>：</p>
<ul>
<li>又学到了一种注入知识到PTMs的方式，我理解为PTM外接神经网络并且固定预训练模型！并且这种方式训练量不大，对构建一个知识引入预训练模型做MRC任务有所启发！</li>
<li>考虑到支持知识continual learning的点值得学习</li>
<li>减少计算量的办法：固定住参数、adapter各自独立训练</li>
<li>在输出层的时候拼接结果，来做下游任务（之前的拼接在中间or输入呢）</li>
<li>多任务学习方法还是很主流，但是也可以不用呢</li>
<li>大神：RoBERTa自身已经具备很强的general 语言知识/语言学知识，LinAdapter对于下游任务的提升并不明显，额外引入的知识和PLM自身的知识有复合的部分。</li>
<li>大神：两个训练K-Adapter的任务，是否适用于学到事实型知识和语言学知识？</li>
<li>大神：如何针对不同的知识设计不同的学习/预训练任务？</li>
<li>transformer依旧是核心，这篇论文针对transformer结构也可以近一步改进</li>
<li>但是如果有GPT3那样的恐怖预训练模型，or针对某个知识领域的训练充分的大预训练模型，这种方法不知道还厉害不厉害。</li>
</ul>
<h4 id="模型方法"><a href="#模型方法" class="headerlink" title="模型方法"></a>模型方法</h4><h5 id="向PTMs里注入知识梳理"><a href="#向PTMs里注入知识梳理" class="headerlink" title="向PTMs里注入知识梳理"></a>向PTMs里注入知识梳理</h5><p>这篇文章中Related Work部分对于<strong>向PLM中注入知识</strong>这一方向进行了很好的梳理，相关工作的区别主要在于 <strong>a) knowledge sources</strong> 和 <strong>b) training objective</strong>；</p>
<img src="https://i.loli.net/2020/06/09/SVBovZILxCqaKRl.png" style="zoom:80%;" />

<h5 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h5><p>作者说这是个高效、灵活的模型，但涉及预训练阶段（预训练模型是冻住的，是对adapters针对不同任务各自预训练）和fine-tune，每个adapter都多个transformer</p>
<img src="https://i.loli.net/2020/06/09/sn3PLKX9kMltUEY.png" style="zoom:80%;" />

<img src="https://i.loli.net/2020/06/09/E6asnHX9IU1G7Bd.png" style="zoom:80%;" />

<p>看adapter的单元结构，是一个神经模型。知识是先各自注入到这些adapter里面去，而不是直接注入到预训练模型里，从而不会引起catastrophic forgetting，也就是说这些是knowledge-specific adapter，预训练模型还是保持原来自己的参数，并且这些adapter会产生对应知识的可分离的表示。然后把预训练模型的输出和adapter层的输出拼起来。</p>
<p>之前的注入方式是通过多任务学习，直接更新预训练模型的参数。</p>
<h5 id="连接方式"><a href="#连接方式" class="headerlink" title="连接方式"></a>连接方式</h5><p>将adapter层连接到PLM中不同的transformer层上</p>
<ul>
<li>当前adapter层的输入：a) transformer层输出的隐藏层，b) 前一个adapter层的输出，这两个表示进行concat</li>
<li>Adapter模型的输出：a) PLM最后一层的隐藏层输出，和 b) 最后一个adapter层的输出，进行concat作为最终的输出；</li>
</ul>
<h5 id="知识注入"><a href="#知识注入" class="headerlink" title="知识注入"></a>知识注入</h5><p>这里注入factual knowledge的方式是：adapter在factual实体关系数据集（T-REx）上做relation classification task.这任务需要adapter模型根据给定的基于context的entity pairs来分类relation labels。然后合并预训练语言模型、adapter的输出。</p>
<p>这里注入linguistic knowledge的方法是：使用斯坦福的依存关系分类工具产生examples，然后在adapter在这些examples上做预训练，目标是预测给定句子里每个token的father index. 然后合并预训练语言模型、adapter的输出。</p>
<h4 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h4><p><strong>预训练-微调阶段</strong></p>
<ul>
<li>不同的Adapter在不同的预训练任务上分别进行训练；</li>
<li>对于不同的下游任务，K-Adapter采用和RoBERTa相同的微调方式；<ul>
<li>只使用一种Adapter时，Adapter模型的最终输出作为task-specific层的输入；</li>
<li>使用多种Adapter时，将多个Adapter模型的输出进行concat作为task-specific层的输入；</li>
</ul>
</li>
</ul>
<h4 id="实验-2"><a href="#实验-2" class="headerlink" title="实验"></a>实验</h4><p>在两种QA任务与上做实验，分别是commonsenseQA(数据集 CosmosQA)和open-domain QA(数据集searchQA和Quasar-T)上做实验。实验结果如下表所示</p>
<p>CosmosQA结合了常识推理，推理复杂、多样，context更长。</p>
<img src="https://i.loli.net/2020/06/09/mPOfvkyYt1H9rei.png" style="zoom:80%;" />



<h3 id="2020-SIGDIAL-Commonsense-Evidence-Generation-and-Injection-in-Reading-Comprehension"><a href="#2020-SIGDIAL-Commonsense-Evidence-Generation-and-Injection-in-Reading-Comprehension" class="headerlink" title="2020_SIGDIAL_Commonsense Evidence Generation and Injection in Reading Comprehension"></a>2020_SIGDIAL_Commonsense Evidence Generation and Injection in Reading Comprehension</h3><h4 id="动机、贡献、启发"><a href="#动机、贡献、启发" class="headerlink" title="动机、贡献、启发"></a>动机、贡献、启发</h4><p>基于常识推理类型的问答有两个特点：1）用于支持回答的信息可能不在P内，2）如何使用外部知识来支持理解，这很难但很重要。</p>
<p>推理所需要证据支持示意图：</p>
<img src="https://i.loli.net/2020/06/28/uCYBDjF65g9qbSf.png" style="zoom:80%;" />

<p>候选答案包含了贴近正确答案的干扰，因此候选答案之间的关系也很重要。</p>
<p>之前的常识推理模型的方法通常是找到一个问题entity和知识图谱的推理路径从而获得answer entity，或者结合图卷积做别的。但一个问题就是，<u>对contextual commonsense reasoning来说，从段落或者问题很难找出仅仅一个最相关的entity来获得正确答案</u>。</p>
<p>其他常识注入PTM然后通过多任务学习更新模型参数的方法，这样注入知识的时候模型参数需要再训练，可能导致灾难性的遗忘。</p>
<p><strong>贡献</strong></p>
<p>CEGI（Commonsense Evidence Generation and Injection）</p>
<ul>
<li><strong>提出了两个evidence generators</strong>，（可以看做输入的辅助信息）<ul>
<li>通过PTM生成<strong>textual evidence generator</strong></li>
<li>从factual knowledge source抽取生成<strong>factual evidence generator</strong>：生成描述出现在P, Q, O里的entity之间相关关系的text</li>
</ul>
</li>
<li>提出了一个<strong>把两种evidences infuse后注入到contextual reasoning PTM的方法，用attention来match</strong></li>
<li>采用胶囊网络来捕获候选答案之间的关系，从而做最后的答案预测。</li>
<li>在CosmosQA上达到了SOTA，比如超过了上文的K-Adapter 2%</li>
</ul>
<p><strong>启发</strong></p>
<ul>
<li>生成的evidence是人类可理解的，并且有助于推理任务</li>
<li>要想办法不让fine-tune造成灾难性遗忘</li>
<li>textual evidence generator是否可以看做文本摘要作为证据支持，这是因为数据集特点，适合用textual evidence generator</li>
<li>层级结构还是很重要的</li>
<li>基于QANet attention的返回来做A-aware B representation，很经典。</li>
</ul>
<h4 id="概要-2"><a href="#概要-2" class="headerlink" title="概要"></a>概要</h4><p>数据集：CosmosQA，没有code</p>
<p>感受：很有逻辑，但模型复杂，很多技术点</p>
<p>方法：</p>
<ul>
<li><p>Evidence Generation</p>
<ul>
<li><p>textual evidence generator</p>
<p>从Q和P中，生成evidence text E=[e1,e2,…ek]，注：k的数量视不同q和paragraph pair而定（我的理解是不仅证据句子数量不同）    </p>
<p>textual evidence generation能观察到textual的一些固有模式or常规信息</p>
</li>
<li><p>factual evidence generator</p>
<p>使用factual knowledge graph来抽取facts and relations，具体略复杂，见论文</p>
</li>
</ul>
</li>
<li><p>Contextual Commonsense Reasoning</p>
<p>Encoder（RoBERTa）生成P,Q,O,E的上下文特征，然后使用类似QANet的attention机制和co-matching来匹配特征pair，最后所有这些pair连接起来送入一个卷积网络来抽取options的不同语义单元，最终后送入一个胶囊网络来动态更新候选options的表示。</p>
<p>其中，Evidence Injection的方式：用类似QANet的attention机制进行evidence Injection。</p>
<p>用CNN来捕获phrase-level patterns</p>
<p>目标是学习一个分类器P(y|P,Q,O,E)</p>
</li>
</ul>
<h4 id="模型与公式"><a href="#模型与公式" class="headerlink" title="模型与公式"></a>模型与公式</h4><img src="https://i.loli.net/2020/06/28/LVxhEAwJTnk9WDl.png" style="zoom:80%;" />

<p>剥离开来看，如果没用证据、也没用胶囊网络，就只是一个encoder+attention(QANet, co-matching)+CNN+prediction而已。</p>
<p>这里也看出，是<strong>在输入的时候，加evidences一起tune的</strong>。（之前K-adapter采用的是在adapter上训练知识，然后和原目标拼接，也没有一起tune）</p>
<p>证据生成部分</p>
<img src="https://i.loli.net/2020/06/29/u9WVrjwsIcPk1zT.png" style="zoom: 67%;" />

<p>textual evidence generation应该能观察到textual的一些固有模式，并且还能考虑到options之间的关系，从而抽取出evidence。在测试阶段，只输入了[P[SEP]Q]，训练的时候是[P[SEP]Q[SEP]O]</p>
<img src="https://i.loli.net/2020/06/29/THpLfwO35unNzDW.png" style="zoom:67%;" />

<p>使用factual knowledge graph来抽取facts and relations，ConceptNet作为base model，Comet来找到和产生新的relations，具体见论文。</p>
<p>为了生成证据，从给定数据里先抽取出entities，然后把相关entity match到subject-relation-object triplets的subject。filter triplets的方法见论文。然后吧这些filtered triplets转化为factual evidences序列。</p>
<h4 id="实验-3"><a href="#实验-3" class="headerlink" title="实验"></a>实验</h4><p>给出了很好的baseline分类：</p>
<img src="https://i.loli.net/2020/06/29/ep4aU7jRygTfiNZ.png" style="zoom:80%;" />

<p>CosmosQA记录</p>
<img src="https://i.loli.net/2020/06/29/5UsQZLnDpqPbSyH.png" style="zoom:80%;" />

<p>消融分析</p>
<img src="https://i.loli.net/2020/06/29/j4pzL8IaVubhco9.png" style="zoom:80%;" />

<p>胶囊网络有效的原因猜测是它抽取出了token-level到phrase-level的层级结构信息。</p>
<h3 id="2019-ACL-Explicit-Utilization-of-General-Knowledge-in-Machine-Reading-Comprehension"><a href="#2019-ACL-Explicit-Utilization-of-General-Knowledge-in-Machine-Reading-Comprehension" class="headerlink" title="2019 ACL_Explicit Utilization of General Knowledge in Machine Reading Comprehension"></a>2019 ACL_Explicit Utilization of General Knowledge in Machine Reading Comprehension</h3><h4 id="动机-1"><a href="#动机-1" class="headerlink" title="动机"></a>动机</h4><ul>
<li><p>MRC模型和人类之间的差距有两方面</p>
<ol>
<li>MRC模型需要大量的训练样例来学习</li>
<li>MRC模型对于有意加入噪声数据不鲁棒</li>
</ol>
</li>
<li><p>造成差距的原因在于目前MRC模型仅利用了给定passage-question对中的信息，而没有像人类一样利用一些 <strong>general knowledge</strong>， 因此这篇文章核心就是把这些general knowledge融入到MRC模型中</p>
</li>
<li><p>MRC融入general knowledge的两个问题</p>
<ul>
<li><p>如何从passage-question paris里抽取general knowledge？</p>
<p>可以用knowledge base的结构化形式存储的通用知识来帮助抽取词之间的信息</p>
</li>
<li><p>如何利用抽取的知识来预测答案span？</p>
<ul>
<li>目前的做法都是隐式地将抽取到的知识的编码，用于增强相应词的lexical/contextual表示</li>
<li>缺点：缺乏解释性和控制性</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h4><ul>
<li><p>会议：2019 ACL</p>
</li>
<li><p>常见的knowledge base:</p>
<p>WordNet(semantic knowledge)，ConceptNet(commonsense knowledge)， Freebase（factoid knowledge）</p>
</li>
<li><p>工作要点：</p>
<ul>
<li>词之间的语义联系（<strong>inter-word semantic connections</strong>）可以作为一种<strong>general knowledge</strong>，例如</li>
</ul>
<img src="https://i.loli.net/2020/04/22/AMvON5bmCjFKefg.png" style="zoom:80%;" />

<ul>
<li><p>提出了一种 <strong>data enrichment</strong> 方法，利用 <strong>WordNet</strong> 作为知识源，为passage-question pair抽取 inter-word semantic connections（<strong>主要是同义词</strong>），抽取是可控的，结果作为MRC明星的general know. </p>
<p>抽取的这些很有助于预测。</p>
</li>
<li><p>提出了一个 <strong>Knowledge Aided Reader（KAR）</strong> 模型，用于显示地将预抽取到的 general knowledge（inter-word semantic connections获取到的） 引入到模型中，并<strong>辅助 attention 机制</strong></p>
</li>
</ul>
</li>
<li><p>结论</p>
<ul>
<li>inter-word semantic connection在小数据上抽取也能用在更大的数据集上</li>
<li>利用词之间的语义连接，使用注意力机制的时候可以只关注最重要的部分而忽略不重要的</li>
</ul>
</li>
</ul>
<h4 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h4><p><strong>data enrichment</strong>的方法，主要是利用同义词集合，然后产生同义词链和拓展同义词集，规定一个超参数来控制拓展同义词集大小，从而抽取信息。抽取详细见：<a target="_blank" rel="noopener" href="http://xingluxi.github.io/2019/07/17/paper-acl2019-kar/">http://xingluxi.github.io/2019/07/17/paper-acl2019-kar/</a></p>
<p><strong>KAR</strong>：显示地利用抽取到的general knowledge来<strong>辅助attention机制</strong>，即<strong>knowledge aided mutual attention</strong>, <strong>knowledge aided self attention</strong>。</p>
<p>attention机制，主要的attention机制有两种，一种是<strong>mutual attention</strong>，把q搞到p里来得到question-aware passage representation，还有一种是<strong>self-attention</strong>，是把question-aware passage的表示再融合到他们自己本身来得到最终的passage representation。</p>
<img src="https://i.loli.net/2020/04/22/LmyQ6xdgzvAoBF3.png" style="zoom:80%;" />

<p>注意看图中的knowledge aided attention，还有knowledge aided similarity matrix，也就是把知识和注意力结合起来来预测答案，得到注意力的核心是需要有构造一个similarity matrix。而因为context包含很多信息，因此<strong>把之前抽取的gk(general know)引入到计算similarity</strong>的过程会更合理</p>
<p>计算相似性用的函数是：<img src="https://i.loli.net/2020/04/22/s9vCK6kadcoglXH.png" style="zoom:80%;" /></p>
<img src="https://i.loli.net/2020/04/22/JB4dlxfVbM9286h.png" style="zoom:67%;" />

<p>而c<sup>*</sup><sub>w</sub>的就是包含知识的词表示，因为之前抽取了同义词集合E<sub>w</sub>，而它能关联到相应词在C<sub>P</sub>的位置，因此得到matching context embedding，然后得到匹配向量c<sub>w</sub>，再过向量合并和外接激活函数最终得到增强的包含知识的词表示。</p>
<p>而在refined memory layer的self-attention融合gk的方式，就是passage中的每个词，只关心和它有同义词关系的其他passage中的词.</p>
<h4 id="实验-4"><a href="#实验-4" class="headerlink" title="实验"></a>实验</h4><img src="https://i.loli.net/2020/04/22/dk5VPmNZGDv7YU9.png" style="zoom:80%;" />

<img src="https://i.loli.net/2020/04/22/GqjAUmFtNMSYVB3.png" style="zoom:90%;" />


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/26/%E4%BB%8ECMRC2019%E5%A4%B4%E9%83%A8%E6%8E%92%E5%90%8D%E7%9C%8B%E4%B8%AD%E6%96%87MRC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zrmm.jpg">
      <meta itemprop="name" content="Changreal">
      <meta itemprop="description" content="博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Changreal">
    </span>

    
    
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/26/%E4%BB%8ECMRC2019%E5%A4%B4%E9%83%A8%E6%8E%92%E5%90%8D%E7%9C%8B%E4%B8%AD%E6%96%87MRC/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2020-08-26 22:13:13 / Modified: 22:12:58" itemprop="dateCreated datePublished" datetime="2020-08-26T22:13:13+08:00">2020-08-26</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="从CMRC2019头部排名看中文MRC"><a href="#从CMRC2019头部排名看中文MRC" class="headerlink" title="从CMRC2019头部排名看中文MRC"></a>从CMRC2019头部排名看中文MRC</h2><p>[TOC]</p>
<h3 id="0-预备知识"><a href="#0-预备知识" class="headerlink" title="0 预备知识"></a>0 预备知识</h3><h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><p><strong>CMRC 2019</strong>的任务是<strong>句子级填空型阅读理解</strong>（Sentence Cloze-Style Machine Reading Comprehension, SC-MRC）。我个人感觉类似7选5 or 5选5的题型。.根据给定的一个叙事篇章以及若干个从篇章中抽取出的句子，参赛者需要建立模型将候选句子精准的填回原篇章中，使之成为完整的一篇文章。SC级的任务提升了MRC难度。</p>
<p>难点：需要根据上下文逻辑关系判断空穴部分；减少干扰项的影响</p>
<p><img src="https://i.loli.net/2020/04/05/CvMnSOuihI3bsK9.png"></p>
<p><strong>数据集样式</strong></p>
<table>
<thead>
<tr>
<th>JSON字段</th>
<th>介绍</th>
</tr>
</thead>
<tbody><tr>
<td>context</td>
<td>带空缺的篇章，空缺以<code>[BLANK]</code>表示</td>
</tr>
<tr>
<td>context_id</td>
<td>篇章的ID, 唯一</td>
</tr>
<tr>
<td>choices</td>
<td>填入空缺内的候选句子，<strong>有序</strong>列表</td>
</tr>
<tr>
<td>answers</td>
<td>填入空缺的句子序号顺序（句子序号从0开始计数）</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<p><strong>JSON举例（包含假选项）</strong></p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;data&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;context&quot;</span>: <span class="string">&quot;森林里有一棵大树，树上有一个鸟窝。[BLANK1]，还从来没有看到过鸟宝宝长什么样。 </span></span><br><span class="line"><span class="string">            小松鼠说：“我爬到树上去看过，鸟宝宝光溜溜的，身上一根羽毛也没有。” “我不相信，”小白兔说，“所有的鸟都是有羽毛的。” </span></span><br><span class="line"><span class="string">            “鸟宝宝没有羽毛。”小松鼠说，“你不信自己去看。” </span></span><br><span class="line"><span class="string">            小白兔不会爬树，它没有办法去看。小白兔说：“我请蓝狐狸去看一看，我相信蓝狐狸的话。” 小松鼠说：“蓝狐狸跟你一样，也不会爬树。” </span></span><br><span class="line"><span class="string">            蓝狐狸说：“我有魔法树叶，我能变成一只狐狸鸟。” [BLANK2]，一下子飞到了树顶上。 “蓝狐狸，你看到了吗？”小白兔在树下大声喊。 </span></span><br><span class="line"><span class="string">            “我看到了，鸟窝里有四只小鸟，他们真是光溜溜的，一根羽毛也没有。”蓝狐狸说。 就在这时候，鸟妈妈和鸟爸爸回来了，</span></span><br><span class="line"><span class="string">            [BLANK3]，....[BLANK8]....&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;choices&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;蓝狐狸是第一次变成狐狸鸟&quot;</span>,</span><br><span class="line">                <span class="string">&quot;森林里所有的鸟听到喊声&quot;</span>,</span><br><span class="line">                <span class="string">&quot;他们看到鸟窝里蹲着一只蓝色的大鸟&quot;</span>,</span><br><span class="line">                <span class="string">&quot;蓝狐狸真的变成了一只蓝色的大鸟&quot;</span>,</span><br><span class="line">                <span class="string">&quot;小动物们只看到过鸟妈妈和鸟爸爸在鸟窝里飞进飞出&quot;</span>,</span><br><span class="line">                <span class="string">&quot;小松鼠变成了一只蓝色的大鸟&quot;</span></span><br><span class="line">                ],</span><br><span class="line">            <span class="attr">&quot;context_id&quot;</span>: <span class="string">&quot;SAMPLE_00002&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;answers&quot;</span>: [<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>]</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><strong>CMRC 2018</strong>的数据集和SQuAD类型相似，来源于中文维基百科，单文档，给定一篇文档和一个问题；参赛者需要解决的是，如何建立并训练 model，使其能更好地理解 context 与 query，并找到相应答案。</p>
<p>在数据方面，主要工作集中在<u>数据的归一化和去噪音</u>。CMRC 比赛训练集包含大约一万条数据，总体数据量偏少，这种情况下<u>数据的标注一致性尤为重要</u>。（标注不一致的问题会使模型的最终预测 EM 指标降低）</p>
<p><strong>相关资讯</strong></p>
<ul>
<li>CMRC官网介绍：<a target="_blank" rel="noopener" href="https://hfl-rc.github.io/cmrc2019/task/">https://hfl-rc.github.io/cmrc2019/task/</a></li>
</ul>
<h4 id="中文MRC任务要点（融合CMRC2018-2019）"><a href="#中文MRC任务要点（融合CMRC2018-2019）" class="headerlink" title="中文MRC任务要点（融合CMRC2018-2019）"></a>中文MRC任务要点（融合CMRC2018-2019）</h4><h5 id="任务类型"><a href="#任务类型" class="headerlink" title="任务类型"></a>任务类型</h5><ul>
<li><p>完形填空</p>
</li>
<li><p>多选</p>
<p>考虑输入拼接方式，比如是单个choice预测 还是 多个choice预测（6estates的启发）</p>
</li>
<li><p>抽取式</p>
</li>
</ul>
<h5 id="数据增强与扩充"><a href="#数据增强与扩充" class="headerlink" title="数据增强与扩充"></a>数据增强与扩充</h5><ul>
<li><p>数据量少</p>
<p>back translatin：比如zh-&gt;en-&gt;zh(哈工大)，过程中保持[blank]位置不变，然后最强增强倍数N=1</p>
<p>用类似领域的数据作为补充；</p>
<p>人工标注（成本花费大）</p>
</li>
<li><p>数据增强方式</p>
<ul>
<li><p>比如多选类型，对答案不属于文章任何一个choice的情况（<em>unknow choice</em>)，做简单DA</p>
</li>
<li><p>又或者动态数据增强（平安）？</p>
</li>
<li><p>又如增加假答案（从原文中随机选取一定数量句子作为候选答案（<strong>增加假答案</strong>）参与训练。（顺丰，CICC是每篇文章会从<u>上一篇文章</u>抽一个句子作为<strong>假例子</strong>）</p>
</li>
<li><p>sample2paras：将所有原文中的 [BLANK] 用 choices 填充，<strong>重新随机生成新的</strong> [BLANK] 位置与对应的 choices，新 [BLANK] 位置的原文长度<u>分布</u>与原始训练集<u>一致</u></p>
</li>
<li><p>生成数据也要考虑去重，比如达到一个阈值或者尝试生成次数上限</p>
</li>
<li><p>设置增强倍数，即每个样本生成N个增强数据</p>
</li>
</ul>
</li>
<li><p>抓取数据</p>
<p>如从故事网等网站上抓取相关文本作为数据集的扩充，并删去相似文本</p>
<p>扩充数据集的时候要注意分布（6estates)，从而生成新数据集</p>
</li>
<li><p>调整问题或者context长度的分布，也要研究一下（6estates和哈工大都有这思想），分布也会涉及重复的样本</p>
</li>
<li><p>增强数据与原始数据的<strong>混合模式</strong>选择</p>
<ul>
<li>增强数据与目标数据领域完全一致</li>
<li>增强数据与目标数据领域有差异（适合迁移 or <strong>stage-wise</strong>）</li>
</ul>
</li>
</ul>
<h5 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h5><ul>
<li><p>文本归一化处理（如：如<u>繁简转换</u>、<u><em>中英文标点转换</em></u>、<u>去除拼音标注</u> 、<u>长度限制</u>、<u>分布调整</u> 等）</p>
</li>
<li><p>增加<u>假答案</u>（从原文中随机选取一定数量句子作为候选答案（假答案）参与训练），CICC是每篇文章会从上一篇文章抽一个句子作为<u>假例子</u></p>
</li>
<li><p>context norm</p>
</li>
<li><p>filter query is None or answer is None</p>
</li>
<li><p>Answer和Context长度限制</p>
</li>
<li><p>data augment</p>
</li>
<li><p>干扰项（CMRC2019）</p>
<p>重复干扰项，排除重复干扰项能明显提高推理效果</p>
<p>随机干扰项</p>
</li>
</ul>
<h5 id="文本向量化表达"><a href="#文本向量化表达" class="headerlink" title="文本向量化表达"></a>文本向量化表达</h5><ul>
<li><p>如用预训练语言模型，如中文ELMo（英文ELMo是基于字符集的编码），可采用的粒度有：</p>
<ul>
<li>中文词级</li>
<li>笔划级</li>
</ul>
</li>
<li><p>字模型</p>
<p>优点：embedding参数少，unk少，语料中字出现的次数相对均匀；</p>
<p>缺点：中文字模型分词后文本可能过长，有些任务分段后性能下降，没有分词的先验信息。</p>
<p><strong>Token level的分类任务(阅读理解，NER等)，字模型&gt;&gt;词模型。</strong>虽然字模型整体表现更好，但是词模型能够有效降低文本长度使得attention视野更远，部分数据集会有奇效。</p>
</li>
<li><p>词模型</p>
<p>优点：有分词的先验信息。有预训练词向量，能够降低文本长度，节约显存。</p>
<p>缺点：Embedding参数巨大，UNK多，词频分布不均带来部分词的优化过于稀疏；week domain transfer ability；目前的分词工具表现还不是很好，会导致下游任务的bias</p>
<p>对于Transformer而言，受限于显存压力。模型大多长度受限，而长距离的attention在很多任务上非常关键，此时词模型对text level的分类任务上可能会有奇效。</p>
<p>通过平安的模型，得知：基于 <strong>sentencepiece</strong>统计得到的 <strong>字词混合模型</strong> 能够基本解决词模型unk的问题，并且在预训练中远优于传统分词+统计得到的词模型。</p>
</li>
<li><p><strong>sub-word</strong> 了解一下咯！</p>
</li>
<li><p>pos embedding</p>
</li>
<li><p>query type embedding</p>
</li>
<li><p>word match</p>
</li>
<li><p>长文档处理（比如结合tramsformer-xl, xlnet的自回归方式处理长文本）</p>
</li>
</ul>
<h5 id="特征融合"><a href="#特征融合" class="headerlink" title="特征融合"></a>特征融合</h5><ul>
<li><p>问题类型的one-hot特征</p>
<p>如：who, where, when, how, num, why, how long等类型，转为one-hot向量</p>
</li>
<li><p>POS信息</p>
</li>
<li><p>词共现特征</p>
</li>
<li><p>句子连贯性</p>
<ul>
<li>候选答案回填（顺丰）</li>
<li>SI，SSI方法（平安）</li>
</ul>
</li>
</ul>
<h5 id="训练方法"><a href="#训练方法" class="headerlink" title="训练方法"></a>训练方法</h5><ul>
<li><p>蒸馏（distill）</p>
<ul>
<li><p>自我蒸馏，self-distill。</p>
<p>自我蒸馏就是不改变模型大小，循环进行 teacher-student 的训练，直到效果不再改进</p>
</li>
<li><p>知识蒸馏</p>
<p>如student采用和teacher同样的网络结构（重生网络）</p>
</li>
</ul>
<p>蒸馏通常用在模型压缩方面，即采用预训练好的复杂模型（teacher model）输出作为监督信号去训练另一个简单模型（student model），从而将 teacher 学习到的知识迁移到 student。</p>
</li>
<li><p>Post-process（要了解）</p>
<p>无监督数据预训练LM -&gt; 特定任务数据上精调LM -&gt; 任务标注数据精调模型（LM初始化）</p>
</li>
<li><p>打破模型训练消耗大对想法尝试的束缚：（CICC）</p>
<p>使用相同原理的tiny模型做benchmark,在其基础上做对比实验，最后应用到大模型上。</p>
</li>
<li><p>多层级任务的pretrain——字、词、句（cicc）</p>
</li>
</ul>
<h5 id="预训练模型"><a href="#预训练模型" class="headerlink" title="预训练模型"></a>预训练模型</h5><ul>
<li>中文预训练BERT-wwm</li>
</ul>
<h5 id="预测目标"><a href="#预测目标" class="headerlink" title="预测目标"></a>预测目标</h5><ul>
<li>level：character level, word level, sentence level</li>
<li>NSP, MSP(6esetates)</li>
<li>这些训练目标和组合，比如同时预测character-level 和mask和mask sentence prediction，不知道能不能看做多任务学习</li>
<li><strong>全词掩码 wwm</strong></li>
</ul>
<p><strong>目标类型</strong></p>
<ul>
<li><p>语言模型</p>
</li>
<li><p>分类问题</p>
</li>
<li><p>合理性排序问题（顺丰），目标决定损失函数</p>
</li>
</ul>
<h5 id="其他：trick-amp-问题"><a href="#其他：trick-amp-问题" class="headerlink" title="其他：trick &amp; 问题"></a>其他：trick &amp; 问题</h5><ul>
<li><p>Gate机制（关注核心单词）</p>
<p>如extra gated-dropout for query</p>
</li>
<li><p>答案抽取用PointerNetwork来预测答案起始与终止位置</p>
<p>prob = start * end</p>
</li>
<li><p>多任务</p>
<ul>
<li>预测词是不是在答案的范围里，二分类，当做辅助任务去训练</li>
<li>预测答案是否在这个句子里</li>
</ul>
<p>多任务其实是比较 trick 的东西，不同任务设置的权重不一样，需要不断去尝试。</p>
</li>
<li><p>显存优化方法</p>
<ul>
<li>blocksparse</li>
<li>避免对大tensor进行dropout</li>
</ul>
</li>
<li><p>中文文档复杂性</p>
<p>当数据集是文本时，文档可能长至几百页，这时，机器就需要搭配<u>文章分类</u>和<u>段落索引</u>这样的技术来提升速度和准确性。</p>
<p>另外，文档中的一级标题、二级标题以及表格和图片等都是需要处理的问题。</p>
</li>
<li><p>学习率</p>
<ul>
<li>学习率自适应，也就是每层组设置不同的学习率（哈工大）</li>
<li>三角周期学习率，学习率按照三角规律周期性变化（与固定学习率的指数衰减方式相比，有明显提升）</li>
</ul>
</li>
<li><p>模型集成， 模型融合</p>
</li>
<li><p>损失函数</p>
<p>marginLoss, CrossEntropyLoss</p>
</li>
</ul>
<h5 id="实用工具"><a href="#实用工具" class="headerlink" title="实用工具"></a>实用工具</h5><ul>
<li><p>了解一下SMRC，搜狗的机器阅读理解工具集合，<a target="_blank" rel="noopener" href="https://github.com/sogou/SMRCToolkit">https://github.com/sogou/SMRCToolkit</a> ，它提供了CMRC2018的模块</p>
</li>
<li><p>blocksparse，一个用于块稀疏矩阵乘法和卷积的高效GPU内核， <a target="_blank" rel="noopener" href="https://github.com/openai/blocksparse">https://github.com/openai/blocksparse</a></p>
</li>
<li><p>SentencePiece(spm)，字词混合模型。作为一个高性能的无监督文本词条化工具，可以通过EM算法为预训练提供基于统计的高效分词。事实上xlnet即是用这个来进行分词的。 <a target="_blank" rel="noopener" href="https://github.com/google/sentencepiece">https://github.com/google/sentencepiece</a> 。</p>
<p>通过平安的模型，得知：基于 <strong>sentencepiece</strong>统计得到的 <strong>字词混合模型</strong> 能够基本解决词模型unk的问题，并且在预训练中远优于传统分词+统计得到的词模型。</p>
</li>
<li><p>中文bert预训练：<a target="_blank" rel="noopener" href="https://github.com/ymcui/Chinese-BERT-wwm">https://github.com/ymcui/Chinese-BERT-wwm</a>  </p>
</li>
</ul>
<h5 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h5><ul>
<li><p>搜索引擎</p>
</li>
<li><p>客服</p>
</li>
<li><p>金融教育领域，有大量非结构化的文本</p>
<p>比如金融有很多公告类型的数据，纯靠人工提取知识点，并且由于长尾效应，难以覆盖到用户需要的所有点。依托阅读理解，机器可以直接从非结构化数据中提取到用户所需要的信息点。</p>
<p>CMRC2019对⾦融⻛控领域， 针对企业年报中关键⾦融要素， 抽取原因语句和相关段落的任务起到帮助 </p>
</li>
</ul>
<h3 id="1-冠军：平安金融"><a href="#1-冠军：平安金融" class="headerlink" title="1 冠军：平安金融"></a>1 冠军：平安金融</h3><h4 id="纲要"><a href="#纲要" class="headerlink" title="纲要"></a>纲要</h4><ul>
<li><p>如何更好地学习到<strong>句子之间的连贯性</strong>？——SI（Sentence Insertion）</p>
</li>
<li><p>非独立性条件下，合理的<strong>预测方式</strong></p>
</li>
<li><p><strong>中文</strong>NLP任务是否还需要<strong>分词</strong>？ ——SentencePiece</p>
</li>
<li><p>预训练模型中连贯性知识的进一步强化 —— SDRP</p>
</li>
<li><p>预训练模型的<strong>领域迁徙</strong> ——SSI</p>
</li>
</ul>
<h4 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h4><p>看来这也是单choice预测策略</p>
<p><img src="https://i.loli.net/2020/04/05/DhSkrxAN7fQiCw8.png"></p>
<h4 id="核心"><a href="#核心" class="headerlink" title="核心"></a>核心</h4><p><strong>优化</strong></p>
<p>针对BERT占用显存的地方优化</p>
<ul>
<li>使用blocksparse</li>
<li>避免对大tensor进行dropout</li>
</ul>
<p><strong>预训练语料</strong></p>
<p>使用多源数据重训练bert，在官方中文BERT使用中文wiki基础上，采集了百科、新闻、知乎等多源数据</p>
<h5 id="连贯性学习"><a href="#连贯性学习" class="headerlink" title="连贯性学习"></a>连贯性学习</h5><p>主题相同的情况下，学习句子的连贯性，并且还要学会拒绝不连贯的句子。</p>
<h6 id="SiBert"><a href="#SiBert" class="headerlink" title="SiBert"></a>SiBert</h6><p><strong>Sentence Insertion（SI代替NSP）</strong></p>
<p>NSP学到的更多是主题信息而不是连贯性信息（根据ALBert研究），因此这里替换NSP为SI；而cmrc2019<u>句子位置预测</u>本身就是一个可用于预训练的<u>自监督方法</u>，能够有效补充<strong>语言模型对<em>连贯性</em> 和 <em>顺序学习</em> 的需求</strong>。</p>
<p>SI能学习到在判断 <strong>主题相同</strong>的情况下，句子放在哪里最连贯。也就是通过创新输入方式，来进行训练。</p>
<p><img src="https://i.loli.net/2020/04/05/K5tZYDBApsEbfLQ.png"></p>
<p>其中，sentence2是其他文档的句子，sentence1-3等是该篇文章，然后mask sentence B的部分，是该篇文章的信息就能学到句子连贯性，不是该篇文章的信息就能学到排除。</p>
<p><strong>SiBert结果与动态mask</strong></p>
<ul>
<li><p>在SiBert基础上基于 <strong>全词MASK</strong>继续fine-tune</p>
</li>
<li><p><strong>全词mask[1]</strong> 与 英文中的ngram-mask相对应，在**spanBert[2]**中表示该方法对MRC提升显著</p>
</li>
</ul>
<img src="https://i.loli.net/2020/04/05/ybPlfa7WBhNuUL8.png" style="zoom:67%;" />





<h6 id="负样本的连贯性"><a href="#负样本的连贯性" class="headerlink" title="负样本的连贯性"></a>负样本的连贯性</h6><p>受到ERNIE2.0[3]的启发，我们为模型新增了Sentence-Document Relation Prediction(<strong>SDRP</strong>)任务。使得模型针对<strong>负样本</strong>不仅仅专注于主题，更能判别它们的<strong>连贯性</strong>。下图结果称为3SiBert（2SiBert见下文），也是在输入构成上做文章。</p>
<p><img src="https://i.loli.net/2020/04/07/RhbtLyYATc2CgUV.png"></p>
<h5 id="非独立性的预测方式"><a href="#非独立性的预测方式" class="headerlink" title="非独立性的预测方式"></a>非独立性的预测方式</h5><p>因为多个choice之间也会提示信息（比如顺序关系，会有对比信息，6estates也有用到这个启发），从而在推断过程中相互提供有效信息得到答案，因此每个choice之间的预测不应该是独立的。</p>
<p>原始的独立的预测目标：</p>
<img src="https://i.loli.net/2020/04/05/3qJyBoOjdTE76fH.png" style="zoom:67%;" />

<p><strong>动态预测</strong></p>
<p>在推断的阶段，逐渐还原文本，增加先验信息，从而动态预测目标。</p>
<p><img src="https://i.loli.net/2020/04/05/kpmrPMKlVhJRxaA.png"></p>
<h5 id="文本长度与分词"><a href="#文本长度与分词" class="headerlink" title="文本长度与分词"></a>文本长度与分词</h5><p><strong>问题</strong></p>
<p>文本长度过长（＞512），限制模型性能，因此要探索如何 <strong>无损缩减长度</strong>， 可以用到 <strong>SentencePiece</strong>[spm]分词工具来降低context文本长度，并得到字词混合模型，能够基本解决词模型unk的问题。</p>
<p><strong>SentencePiece</strong></p>
<p>高性能的无监督文本词条化工具，可以通过EM算法为预训练提供基于统计的高效分词，并得到字词混合模型，能够基本解决词模型unk的问题。下图里，分词后context长度明显降低。（2SiBert）</p>
<img src="https://i.loli.net/2020/04/06/7c3zfHh4QvnMubO.png" style="zoom: 80%;" />

<p>Sibert vs 2Sibert结论：</p>
<ul>
<li>基于sentencepiece统计得到的字词混合模型能够基本解决词模型UNK的问题，在预训练中远优于传统分词+统计得到的词模型。</li>
<li>Token level的分类任务(阅读理解，NER等)，字模型&gt;&gt;词模型。</li>
</ul>
<h5 id="动态数据增强与领域迁移"><a href="#动态数据增强与领域迁移" class="headerlink" title="动态数据增强与领域迁移"></a>动态数据增强与领域迁移</h5><p>为了使得预训练模型更贴近cmrc2019的任务，在之前预训练模型的基础上把Sentence Insertion任务替换为短句抽取(<strong>Short Sentence Insertion, SSI</strong>)，进一步训练了500k步。</p>
<p><img src="https://i.loli.net/2020/04/05/HhA8WYNq7str3C2.png"></p>
<h4 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h4><p><img src="https://i.loli.net/2020/04/05/38HFotdpklg7Ky5.png"></p>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul>
<li><p>预训练</p>
<p>BERT模型优化，预训练语料丰富化；<strong>Sentence Insertion</strong> 和 <strong>全词mask</strong>任务；句子篇章关系预测任务；预训练模型的领域迁移</p>
</li>
<li><p>数据增强</p>
<p>简单负样本增强；动态数据增强（配合SDRP）</p>
</li>
<li><p>数据处理</p>
<p>SentencePiece字词混合模型； 动态预测</p>
</li>
</ul>
<h3 id="2-亚军：顺丰-Mojito-System"><a href="#2-亚军：顺丰-Mojito-System" class="headerlink" title="2 亚军：顺丰 Mojito System"></a>2 亚军：顺丰 Mojito System</h3><h4 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h4><ul>
<li>数据清理</li>
<li>增加假答案</li>
<li>候选答案回填（判断句子 <strong>合理性、连贯性</strong>）</li>
<li>多**[mask]填充**（与掩码语言模型保持一致性、一定程度上还原候选答案与上下文的相对距离）</li>
</ul>
<p><img src="https://i.loli.net/2020/04/05/utvSGrQMOIP8byn.png"></p>
<p>区分mask和blank哦</p>
<h4 id="预训练"><a href="#预训练" class="headerlink" title="预训练"></a>预训练</h4><p><img src="https://i.loli.net/2020/04/05/gzp1vXYZyENBesT.png"></p>
<h4 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h4><p><img src="https://i.loli.net/2020/04/05/Mnwya1HrfkNWCPo.png"></p>
<p><img src="https://i.loli.net/2020/04/05/RzT7cPtryxd4XmM.png"></p>
<p><strong>Margin Loss</strong></p>
<p>候选答案是一个 <strong>合理性排序问题</strong>！ 而不是分类问题</p>
<img src="https://i.loli.net/2020/04/05/lD7W84o1HTvxn9t.png" style="zoom:67%;" />

<p><strong>知识蒸馏</strong>，重生网络，对应的loss</p>
<p><img src="https://i.loli.net/2020/04/05/1hMJGa4FSfulCLP.png"></p>
<h4 id="预测策略"><a href="#预测策略" class="headerlink" title="预测策略"></a>预测策略</h4><p>关键是构造这个候选答案的<strong>得分矩阵</strong>（下文6estates的是choice-unused矩阵，反正关键是构建矩阵），在这个基础上采用 <strong>差值排序</strong>。</p>
<p>有图知，答案的选择策略有两种，一种的方案A直接取最高分，还有一种是方案B采用差值排序选择。</p>
<img src="https://i.loli.net/2020/04/05/nH1khN7Z8KReYEq.png" style="zoom:80%;" />

<h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><img src="https://i.loli.net/2020/04/05/oah2jvKuZGXD8Wm.png" style="zoom:80%;" />

<p>总之有和其他模型的对比；自己的消融分析；采用不同预训练语言模型的对比；采用集成模型的对比</p>
<h4 id="错误分析"><a href="#错误分析" class="headerlink" title="错误分析"></a>错误分析</h4><p>对于需要一些推理的blank（好像不同的方法叫法不同，在6esetate里不知道是不是又处理了，叫作unsed），观察出缺乏一定<u>知识推理能力</u>；候选答案无法区分，答案都合理；预测方案不同导致不同的预测答案；关键上下文缺失的情况下，已有信息无法得到真正的答案；语序方面的问题；</p>
<h3 id="3-季军：6Estates"><a href="#3-季军：6Estates" class="headerlink" title="3 季军：6Estates"></a>3 季军：6Estates</h3><h4 id="数据集分析"><a href="#数据集分析" class="headerlink" title="数据集分析"></a>数据集分析</h4><p><strong>问题</strong></p>
<ol>
<li>数据不充分；</li>
<li>TTD数据问题数量分布差异； （结合1，所以可以考虑自己增加一些数据集）</li>
<li>TTD 文本长度分布也有差异；</li>
<li>相似文本值得答案有所泄露或者互相干扰</li>
</ol>
<p><img src="https://i.loli.net/2020/04/06/9HdDV8a1JTmf4OA.png"></p>
<p><img src="https://i.loli.net/2020/04/06/EzhQG2up7XsZ1rR.png"></p>
<img src="https://i.loli.net/2020/04/06/TDLKZ5zhopAseq2.png" style="zoom:80%;" />





<h4 id="策略与方法"><a href="#策略与方法" class="headerlink" title="策略与方法"></a>策略与方法</h4><p><strong>策略</strong></p>
<ul>
<li>改进bert</li>
<li>增加数据量，并调整数据分布（研究一下）</li>
<li>尝试不同预训练任务</li>
<li>问题转化为针对context构建 <strong>choice-unused</strong> 概率矩阵</li>
<li>分别以choice 和 unused 为中心构建不同模型进行预测</li>
</ul>
<p>矩阵如图：</p>
<img src="https://i.loli.net/2020/04/06/QrpsoT63IWZOh9R.png" style="zoom:90%;" />



<h5 id="数据集扩充，分布调整"><a href="#数据集扩充，分布调整" class="headerlink" title="数据集扩充，分布调整"></a>数据集扩充，分布调整</h5><ul>
<li>从故事网等网站抓取更多相关文本；删去trail/dev/qualify中的相似文本；</li>
<li>问题可以包含符号，字符长度15-30，问题数量5-15；不允许采样时出现相似文本，从而生成新的数据集</li>
</ul>
<h5 id="预训练-1"><a href="#预训练-1" class="headerlink" title="预训练"></a>预训练</h5><p>预训练的几种objective，这就涉及多任务学习的范畴</p>
<ul>
<li>在新数据上⽣成了⼤约600W预训练数据  </li>
<li>Mask Prediction 1（character level）  </li>
<li>Mask Prediction 2 （word level）  </li>
<li>Next Sentence Prediction</li>
<li>Mask Sentence Prediction  </li>
</ul>
<img src="https://i.loli.net/2020/04/06/JRlrbdkp2MafTuW.png" style="zoom:67%;" />

<img src="https://i.loli.net/2020/04/06/AGjzlx6UrNw18K9.png" style="zoom:67%;" />



<h5 id="单个choice拼接预测"><a href="#单个choice拼接预测" class="headerlink" title="单个choice拼接预测"></a>单个choice拼接预测</h5><p>将单个choice放入一个example中，从而训练新的预训练模型。</p>
<p>由此产生发方法有：</p>
<ul>
<li>model1 : 新的预训练模型</li>
<li>model2 : 新的与训练模型 + 更大训练集</li>
<li>model3 : 加⼊更多中间层， 在最终输出层之前增加更⾼概率的Dropout  </li>
<li>model4 : 增加单独的输出和Attention⽤来<strong>检测是否为假的Choice</strong>   （这个和平安的有所相似）</li>
</ul>
<img src="https://i.loli.net/2020/04/06/RvmdVqbeLH8lcDQ.png" style="zoom: 67%;" />



<h5 id="多个choice拼接预测"><a href="#多个choice拼接预测" class="headerlink" title="多个choice拼接预测"></a>多个choice拼接预测</h5><p>所有choice都放入一个example中，从而建模的时候做choice rep和unused rep的text pooling</p>
<img src="https://i.loli.net/2020/04/06/fvImiAlHwo52TkE.png" style="zoom:80%;" />

<img src="https://i.loli.net/2020/04/06/SkPHhfbmxTrANYZ.png" style="zoom:80%;" />

<h5 id="多choice-vs-单choice"><a href="#多choice-vs-单choice" class="headerlink" title="多choice vs 单choice"></a>多choice vs 单choice</h5><ul>
<li>当需要⻓⽂本上下⽂来辅助判断时，同样max_seq_len情况下多 choice模型能够建模的context⻓度⼤⼤减少  （可以结合xlnet的自回归建模方式处理长文档）</li>
<li>当存在有多个空位距离较近时， 需要更多的<strong>choice之间的对⽐信息</strong>（顺丰也考虑到这个，就是choice之间的关系）才能辅助确定空位应该填⼊的choice  </li>
</ul>
<h5 id="集成模型"><a href="#集成模型" class="headerlink" title="集成模型"></a>集成模型</h5><ol>
<li>单choice和多choice模型预测<strong>概率线性回归</strong>  </li>
<li>根据choice预测概率和choice部分⽂本在context中的出现情况判断是否直接排除该choice  </li>
<li>将置信度较⾼的choice填⼊context中， 构建新的case， <strong>迭代式预测</strong>  </li>
</ol>
<h4 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h4><ul>
<li>长文档，xlnet的自回归思想建模方式，处理更长文本</li>
<li>多choice模型中增加更合适的pairwise loss，使得模型能在choice选取中更有区分度</li>
</ul>
<h3 id="4-季军：哈工大"><a href="#4-季军：哈工大" class="headerlink" title="4 季军：哈工大"></a>4 季军：哈工大</h3><h4 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h4><img src="https://i.loli.net/2020/04/06/lPskJtxyvHKWDF8.png" style="zoom:80%;" />

<p><strong>创新点：</strong></p>
<p>个人感觉主要是在<u>数据</u>、训练方式上做加法，模型架构没有什么创新</p>
<ol>
<li><p>提出了一种填空型阅读理解任务的<strong>通用数据增强方法</strong></p>
</li>
<li><p>在特定任务数据上<strong>精调 LM</strong> 明显地提升了语言模型对该任务的表达能力</p>
</li>
<li><p>学习率的领域自适应与三角周期性学习</p>
</li>
<li><p>数据增强与原始数据的<strong>混合模式选择</strong></p>
</li>
</ol>
<p><strong>优点</strong></p>
<ul>
<li>单模型，训练及推理效率高</li>
<li>通用数据增强方法可使用<strong>其他领域数据做迁移</strong>或者<strong>从任意领域无监督数据直接生成训练集</strong></li>
</ul>
<p><strong>改进</strong></p>
<ul>
<li>模型结构上有待进一步改进，如加入更能<u>表征句子位置的结构</u></li>
<li>对每个样本的多个 choice 位置的损失加入整体性约束</li>
</ul>
<h4 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h4><ol>
<li><p>重排填空位置</p>
<p><img src="https://i.loli.net/2020/04/07/r8EXhDtlMQejGB2.png"></p>
</li>
<li><p>Back Translate</p>
<ul>
<li>zh-&gt;en-&gt;zh：保持 [BLANK] 位置不变</li>
<li>最佳增强倍数 N=1：使用重排对每个样本生成1个增强数据</li>
</ul>
</li>
</ol>
<h4 id="学习率"><a href="#学习率" class="headerlink" title="学习率"></a>学习率</h4><p><strong>学习率领域自适应</strong></p>
<p><img src="https://i.loli.net/2020/04/07/7afWR2s9MlmTvDi.png"></p>
<p><strong>三角周期学习率</strong>：学习率按照三角规律周期性变化</p>
<h4 id="训练方法-1"><a href="#训练方法-1" class="headerlink" title="训练方法"></a>训练方法</h4><img src="https://i.loli.net/2020/04/07/LrJHgYxc5e3PKQz.png" style="zoom:67%;" />

<h4 id="数据增强与原始数据的-混合模式-选择"><a href="#数据增强与原始数据的-混合模式-选择" class="headerlink" title="数据增强与原始数据的 混合模式 选择"></a>数据增强与原始数据的 混合模式 选择</h4><ol>
<li><p>增强数据与目标数据领域完全一致</p>
<img src="https://i.loli.net/2020/04/07/mvLkRPVIji4CFlz.png" style="zoom:67%;" />
</li>
<li><p>增强数据与目标数据领域有差异</p>
<ul>
<li>适合迁移：增强数据模型-&gt;目标数据模型</li>
<li><strong>stage_wise</strong>: 从距离最远的优先训练，依次迁移到距离较近的增强数据，最后迁移到目标数据，这样有效利用其它领域信息并减少遗忘</li>
</ul>
</li>
<li><p>该句子填空任务的增强数据与目标数据领域完全一致</p>
<p><img src="https://i.loli.net/2020/04/07/7ywZhm6NodjpSUD.png"></p>
</li>
</ol>
<h4 id="排除干扰项"><a href="#排除干扰项" class="headerlink" title="排除干扰项"></a>排除干扰项</h4><img src="https://i.loli.net/2020/04/07/VeYMd2Hg5U3QCbS.png" style="zoom: 67%;" />

<h4 id="实验结果-1"><a href="#实验结果-1" class="headerlink" title="实验结果"></a>实验结果</h4><img src="https://i.loli.net/2020/04/07/SY7sKgNJl4z8eLj.png" style="zoom:67%;" />



<h3 id="5-季军：CICC"><a href="#5-季军：CICC" class="headerlink" title="5 季军：CICC"></a>5 季军：CICC</h3><h4 id="实验结果和消融分析"><a href="#实验结果和消融分析" class="headerlink" title="实验结果和消融分析"></a>实验结果和消融分析</h4><img src="https://i.loli.net/2020/04/07/qovx3YpsjhrgmyC.png" style="zoom:67%;" />

<p>由上图知：</p>
<ul>
<li><p>增加假例子：每篇文章会从上一篇文章抽一个句子作为假例子</p>
</li>
<li><p>domain pretrain</p>
<img src="https://i.loli.net/2020/04/07/NkSHlsXVUnguJdx.png" style="zoom:67%;" />
</li>
<li><p>mix pretrain</p>
</li>
<li><p>阅读理解策略</p>
<img src="https://i.loli.net/2020/04/07/JfVN54x9sKlB6ir.png" style="zoom:67%;" />
</li>
<li><p>三模型融合</p>
<img src="https://i.loli.net/2020/04/07/yoaGfIJknuw1WRe.png" style="zoom: 80%;" />

<h4 id="反思"><a href="#反思" class="headerlink" title="反思"></a>反思</h4><p><strong>如何打破模型训练消耗大对想法尝试的束缚</strong>：</p>
<p>使用相同原理的tiny模型做benchmark,在其基础上做对比实验，最后应用到大模型上。</p>
<p><strong>多层级任务的pretrain——字、词、句</strong></p>
<img src="https://i.loli.net/2020/04/07/BDcTEodK4yFbCa8.png" style="zoom:67%;" />

</li>
</ul>
<h3 id="6-启发"><a href="#6-启发" class="headerlink" title="6 启发"></a>6 启发</h3><p><strong>动机</strong>出发，比如探索更好的MRC落地应用，或者探索PTM的新的任务。通过改进不同模型的缺点来找到创新点和推动发展。</p>
<p>根据具体数据集<strong>任务分析</strong>数据集好像是个之前被我很忽略的一个点，这里好几个队伍都对进行了数据集的分析，从而观察数据集的分布、选项、长度、数据数量、重复项，判断选项之间的顺序性或者独立性影响，选项与上下文之间的影响作用，这都是我之前没有考虑到的！分析任务是个首当其中的大事啊！分析任务还包括分析任务的难点，比如这个任务的难点就包括句子连贯性的学习，因此针对连贯性，冠军也亚军团队都有自己的连贯性学习方案，具体见上文因为这里我突然想不起来了（记性真的好差，因此要多回顾呀）。</p>
<p>每个模型基本都使用了<strong>数据增强</strong>来拓展数据集，其中包括增强方案、领域迁移、back translate、生成假数据、假答案、简单粗暴抓取数据等不同的拓展数据的方式与数据混合方式，并且对原始的数据与生成的数据也要做进一步的<strong>处理</strong>比如分布调整、去重等，但我对这些方面的认识还是十分模糊！如果要做中文MRC任务，这方面我还要多下点功夫研究和归纳一下，数据的扩充和处理是个大任务！</p>
<p>在模型的输入上面，也有讲究（尤其是平安科技），比如输入的数据来源策略、组合方式、怎么mask、是否进行数据增强等，是否有分词（如果有分词，那么分词工具是什么？分词粒度是什么？）善用[cls]的信息哦，这对模型的效果也有很大影响。输出预测方式上也有tips。</p>
<p>适合中文任务的<strong>预训练模型</strong>也要了解哦，比如常用的bert-wwm，这是个啥玩意？快去搞！（搞了搞了）</p>
<p>spanBert似乎是2019的实用方法，在mask词上有所帮助；总之在<strong>语言模型</strong>的 <strong>mask</strong> 上面要看些论文了，估计其中一部分论文还要从预训练模型里面找。</p>
<p>采用<strong>Post-training</strong>的multi-task方法再次在顺丰的模型上证明，多任务学习的损失loss的设计，涉及数学知识的部分如何把握？还有有点担心计算量，又预训练又post training的，我们学校的服务器能跑多少？还是只能跑fine-tune？也许这需要一个很轻便的预训练模型吧？这点要找学长问问，以及问问学长做过哪些训练实验，如果能发现能直接拿来用的实验结果就更好了。看到CICC那边对于到模型消耗大的反思，我也要有所启发，比如如何构建一个相同原理的tiny模型来组benmark？</p>
<p>上面也设计到训练方式，训练方式里的各种<strong>蒸馏</strong>也可以了解一下呢，知识蒸馏是啥？快去看呐。</p>
<p>中文MRC的训练单位，及词、字作为输入单位的不同特点，中文还是需要分词的；而在cicc看到多层级的任务的预训练：<strong>字、词、句</strong>，这方面学习到的知识如何抽取和融合利用，也要探索。</p>
<p>大部分模型的输入，好像还是单个choice拼接context的，学习打分的矩阵很关键，即得到一个交融的矩阵还是很重要的；模型的<strong>预测目标设计</strong>上，要针对数据集的特点，思考要让模型学到什么。并且预测的类型也可以不一样，比如多选题的目标可以是分类，而又可以是一个排序问题（多个选项中找最高可能）；</p>
<p>最后还要拥有一种 <strong>分析思想</strong>，要总结经典套路的<strong>消融分析</strong>、<strong>错误分析</strong>方式，还要结合模型特点和创新点来设置分析对比实验，并且还可以从任务特点来做分析，比如CICC的对不同位置的结果也可以做分析，总之能找出问题的话，就可以找出可改进的地方。在消融分析上做减法或者做加法都可，涉及的组件比如预训练组件、语言模型差异、数据的增强方法（比如领域迁移、假答案等）、训练方式的不同（比如融合模型）。总之这里的分析思想也和上面的任务分析思想对应，要多分析，多思考，想不出来抱大腿（不是。</p>
<p>看论文的时候不仅要学会找能用的东西，还要思考自己能不能创新？就是既要思考模型的优点，更要找到模型的缺点，但是目前我好像还是只在汲取知识的阶段，缺点根本看不出来好伐。。因为要看的太多了，找到一些可用的素材就已经很难，找到关系更是难上加难，如果要创新的话，怎么站在巨人的肩膀上？更如何在错综复杂的关系里选择合适的轮子？如果专注于造轮子的话如何稳住心态不会崩？</p>
<h3 id="7-参考"><a href="#7-参考" class="headerlink" title="7 参考"></a>7 参考</h3><h4 id="网页"><a href="#网页" class="headerlink" title="网页"></a>网页</h4><p><a target="_blank" rel="noopener" href="https://www.leiphone.com/news/201811/3KC2OSaNQDzhTDDJ.html">https://www.leiphone.com/news/201811/3KC2OSaNQDzhTDDJ.html</a></p>
<p>雷锋网的RC进阶：<a target="_blank" rel="noopener" href="https://www.leiphone.com/news/201811/wr62uxvN0dJDbLwF.html">https://www.leiphone.com/news/201811/wr62uxvN0dJDbLwF.html</a> ，2018</p>
<p>从字到词，大词典中文BERT模型的探索之旅，<a target="_blank" rel="noopener" href="https://www.jiqizhixin.com/articles/2019-06-27-17?from=synced&amp;keyword=%E8%AF%8D%E5%90%91%E9%87%8FBERT">https://www.jiqizhixin.com/articles/2019-06-27-17?from=synced&amp;keyword=%E8%AF%8D%E5%90%91%E9%87%8FBERT</a></p>
<h4 id="ppt提到的论文"><a href="#ppt提到的论文" class="headerlink" title="ppt提到的论文"></a>ppt提到的论文</h4><ul>
<li><p>[1] Cui, Yiming, et al. “Pre-Training with Whole Word Masking for Chinese BERT.” arXiv preprint arXiv:1906.08101 (2019) 【中文预训练BERT-wwm】</p>
</li>
<li><p>[2] Joshi M, Chen D, Liu Y, et al. Spanbert: Improving pre-training by representing and predicting spans[J]. arXiv preprint arXiv:1907.10529, 2019.  【 平安、顺丰，动态mask和spanmask】</p>
</li>
<li><p>[3] Sun, Yu, et al. “Ernie 2.0: A continual pre-training framework for language understanding.” arXiv preprint arXiv:1907.12412 (2019).</p>
</li>
<li><p>[4] Li, Xiaoya, et al. “Is word segmentation necessary for deep learning of Chinese representations?.” Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 2019.</p>
</li>
<li><p>[5] Furlanello T, Lipton Z C, Tschannen M, et al. Born again neural networks. International Conference on Machine Learning (ICML), 2018  【重生网络】【知识蒸馏】</p>
</li>
<li><p>[6] Clark K, Luong M T, Khandelwal U, et al. Bam! born-again multi-task networks for natural language understanding. Association for Computational Linguistics (ACL), 2019.  【重生网络的一种策略】</p>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
  
  
  


  



      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Changreal</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  















  








  

  

</body>
</html>
